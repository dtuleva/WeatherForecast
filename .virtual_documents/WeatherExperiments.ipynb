%matplotlib inline


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
#import seaborn as sns

import mlflow

from matplotlib.patches import Patch

from sklearn.compose import make_column_selector, ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, max_error, PredictionErrorDisplay
from sklearn.model_selection import TimeSeriesSplit, cross_validate, GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler, FunctionTransformer, MultiLabelBinarizer, OneHotEncoder, PolynomialFeatures
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import PCA, KernelPCA



import sys

# print(sys.executable)
print(sys.version)








def create_lags(dataframe, column_list, n_lags):
    """
    Creates lags for the specified columns.
    Returns pandas DataFrame.
    """
    # TODO: check datetime order and missing days
    
    if type(column_list) == str:
        column_list = [column_list]

    lags = range(1, n_lags + 1)

    lags_dataframe = dataframe[column_list].shift(lags)

    assert dataframe.shape[0] == lags_dataframe.shape[0]

    return lags_dataframe


def plot_residuals(y_true, y_pred, feature):
    
    fig, axs = plt.subplots(ncols=2, figsize=(10, 4))
    
    PredictionErrorDisplay.from_predictions(
        y_true,
        y_pred=y_pred,
        kind="actual_vs_predicted",
        ax=axs[0]
    )
    axs[0].set_title("Actual vs. Predicted values")
    
    PredictionErrorDisplay.from_predictions(
        y_true,
        y_pred=y_pred,
        kind="residual_vs_predicted",
        ax=axs[1]
    )
    axs[1].set_title("Residuals vs. Predicted Values")
    
    fig.suptitle(feature)
    plt.tight_layout()
    plt.show()


def plot_residuals_vs_time(y_actual, y_predicted, feature, dataframe):
    plt.figure(figsize=(12, 6))
    
    plt.scatter(dataframe.datetime[y_actual.index], y_predicted - y_actual)

    for year in dataframe.datetime.dt.year.unique(): 
        plt.axvline(pd.Timestamp(year, 1, 1), c = "lightgrey", ls = "--")
    
    plt.title(f"{feature} - Residuals vs. Datetime")
    plt.show()


def plot_cv_indices(cv, X, ax, fig, n_splits, lw=10):
    """
    Create a sample plot for indices of a cross-validation object.
    Function copied (with few adjustments) from sklearn documentation at
    https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py
    """

    cmap_cv = plt.cm.summer
    cmap_year = plt.cm.viridis
    cmap_precip = plt.cm.Blues
    cmap_temp = plt.cm.coolwarm
    cmap_cloudcover = plt.cm.Grays

    # Generate the training/testing visualizations for each CV split
    for ii, (tr, tt) in enumerate(cv.split(X=X, y=X.temp, groups=X.dt_year)):
        # Fill in indices with the training/test groups
        indices = np.array([np.nan] * len(X))
        indices[tt] = 1
        indices[tr] = 0

        # Visualize the results
        ax.scatter(
            range(len(indices)),
            [ii + 0.5] * len(indices),
            c=indices,
            marker="_",
            lw=lw,
            cmap=cmap_cv,
            vmin=-0.2,
            vmax=1.2,
        )

    # Plot the data targets and years at the end    
    temp_scatter = ax.scatter(
        range(len(X)), [ii + 1.5] * len(X), c=X.temp, marker="_", lw=lw, cmap=cmap_temp, label = "temp"
    )

    precip_scatter = ax.scatter(
        range(len(X)), [ii + 2.5] * len(X), c=X.precip, marker="_", lw=lw, cmap=cmap_precip
    )

    cloudcover_scatter = ax.scatter(
        range(len(X)), [ii + 3.5] * len(X), c=X.cloudcover, marker="_", lw=lw, cmap=cmap_cloudcover
    )

    year_scatter = ax.scatter(
        range(len(X)), [ii + 4.5] * len(X), c=X.dt_year, marker="_", lw=lw, cmap=cmap_year
    )

    # Formatting
    yticklabels = list(range(n_splits)) + ["temp", "precip", "cloudcover", "year"]
    ax.set(
        yticks=np.arange(n_splits + 4) + 0.5,
        yticklabels=yticklabels,
        xlabel="Sample index (days)",
        ylabel="CV iteration",
        ylim=[n_splits + 4.2, -0.2],
        xlim=[0, 1000],
    )
    ax.set_title("{}".format(type(cv).__name__), fontsize=15)

    
    # Add colorbars
   
    plt.colorbar(temp_scatter, cax = fig.add_axes([0.95, 0.5, 0.3, 0.02]), orientation="horizontal").set_label(label = "Temperature [C$\degree$]", size=8)
    plt.colorbar(precip_scatter, cax = fig.add_axes([0.95, 0.35, 0.3, 0.02]), orientation="horizontal").set_label(label="Precipitation [mm]", size=8)
    plt.colorbar(cloudcover_scatter, cax = fig.add_axes([0.95, 0.2, 0.3, 0.02]), orientation="horizontal").set_label(label="Cloud Cover [%]", size=8)
    
    ax.legend(
        [Patch(color=cmap_cv(0.02)), Patch(color=cmap_cv(0.8)),
         Patch(color=cmap_year(0.02)), Patch(color=cmap_year(0.5)),Patch(color=cmap_year(0.98))],
        ["Training set", "Validation set", "2021", "2022", "2023"],
        loc=(1.02, 0.7),
    )
    
    return ax


def plot_score_cv(cv_results, target = "temp", score_metrics = ("r2", "neg_mean_squared_error", "neg_mean_absolute_error", "max_error"), skip_folds = 0):
    
    fig, axs = plt.subplots(2, 2, figsize=(12, 6), constrained_layout = True)
    fig.suptitle(f"Cross Validation Scores, Target: {target}")

    
    n_folds = len(cv_results["test_r2"])
    fold_indices = np.arange(n_folds)


    for metric, ax in zip(score_metrics, axs.flat):
        
        ax.plot(fold_indices[skip_folds:], cv_results[f"train_{metric}"][skip_folds:], label = "train")
        ax.plot(fold_indices[skip_folds:], cv_results[f"test_{metric}"][skip_folds:], label = "validation")

        ax.set_xlabel("Fold index")
        ax.set_xticks(fold_indices)
        ax.set_ylabel(metric)
        ax.legend()
    
    plt.show()


def plot_cv_predictions(cv_results, input_dataframe, target_column, n_fold = -1):
    plt.figure(figsize=(13, 4))

    
    estimator = cv_results["estimator"][n_fold]
    
    plt.plot(input_dataframe.datetime, input_dataframe[target_column], c = "lime", lw = 1, label = "actual values") # y_true
    
    indices_train = cv_results["indices"]["train"][n_fold]
    predictions_train = estimator.predict(input_dataframe.loc[indices_train])
    plt.plot(input_dataframe.datetime.loc[indices_train], predictions_train, lw = 1, label = "predictions train set")

    indices_test = cv_results["indices"]["test"][n_fold]
    predictions_test = estimator.predict(input_dataframe.loc[indices_test])
    plt.plot(input_dataframe.datetime.loc[indices_test], predictions_test, lw = 1, label = "predictions validation set")

    plt.title(f"Predictions of Model trained on Fold {n_fold}")
    plt.ylabel(target_column)
    plt.legend()

    plt.show()



def run_cv_experiment(
        estimator, 
        X, 
        y, 
        cv, # instance of TimeSiresSplit or KFold
        scoring_metrics = ("r2", "neg_mean_squared_error", "neg_mean_absolute_error", "max_error"), 
        log_experiment = False, 
        experiment_name = "", 
        target_name = ""
        ):

    assert isinstance(cv, TimeSeriesSplit), "cv must be an instance of TimeSeriesSplit, no index sequence allowed"
    
    cv_results = cross_validate(
        estimator, # Estimator
        X, # X
        y, # y
        scoring = scoring_metrics, 
        cv = cv, 
        return_train_score = True, 
        return_indices = True,
        return_estimator = True
        )

    if log_experiment is False:
        return cv_results

    feature_names = None
    feature_count = 0
    try:
        feature_names = estimator[-2].get_feature_names_out()
        feature_count = len(feature_names)
        feature_names = [feat for feat in estimator[-2].get_feature_names_out() if ("_lag_2" in feat or "dt_" in feat)]
    except(AttributeError):
        feature_names = "Estimator does not provide get_feature_names_out"
    
    experiment = mlflow.create_experiment(name = f"{experiment_name}_{feature_count}_features_{target_name}")
    
    n_folds = cv.n_splits
    
    for run_idx in range(n_folds):
        with mlflow.start_run(experiment_id = experiment, run_name=f"fold_{run_idx}"):
            
            mlflow.log_param("cv_n_folds", n_folds)
            mlflow.log_param("cv_type", cv.__class__.__name__)
            mlflow.log_param("target", target_name)
            mlflow.log_param("n_samples_train", len(cv_results["indices"]["train"][run_idx]))
            mlflow.log_param("n_samples_test", len(cv_results["indices"]["test"][run_idx]))
            mlflow.log_param("feature_names", feature_names)
            mlflow.log_param("feature_count", feature_count)
            
    
            for metric in scoring_metrics:
                test_metric_key = f"test_{metric}"
                train_metric_key = f"train_{metric}"
                mlflow.log_metric(test_metric_key, cv_results[test_metric_key][run_idx])
                mlflow.log_metric(train_metric_key, cv_results[train_metric_key][run_idx])

    return cv_results



def run_grid_search(
        estimator,
        X,
        y,
        param_grid,
        cv,
        scoring_metrics = ("r2", "neg_mean_squared_error", "neg_mean_absolute_error", "max_error"),
        run_name = "", 
        target = "temp",
        pca_kernel = "",
        log_run = False,
        experiment = "372952805905307120"):
    
    grid_search = GridSearchCV(
    estimator, 
    param_grid = param_grid,
    cv = cv,
    scoring = scoring_metrics,
    refit = "neg_mean_squared_error", # choose best model based on mse
    return_train_score = True
    )

    grid_search.fit(X, y)

    result = grid_search.cv_results_

    gridsearch_results_df = pd.DataFrame(result)

    if log_run is False:
        
        return(grid_search, gridsearch_results_df)
    
    
    with mlflow.start_run(experiment_id = experiment, run_name = run_name) as run:
        mlflow.log_param("target", target)
        mlflow.log_param("pca_kernel", pca_kernel)
        mlflow.log_params(param_grid)

        file = f"output_gridsearch/gridsearch_{target}_{run_name}"
        gridsearch_results_df.to_csv(file, index=False)
        mlflow.log_artifact(file)
        mlflow.log_params({f"best_{key}": value for key, value in grid_search.best_params_.items()})  
        
        return(grid_search, gridsearch_results_df)


def filter_grid_search_df(dataframe, metric = "r2", n_best = 5):
        
        # "r2": "r2",
        # "mse": "neg_mean_squared_error",
        # "mae": "neg_mean_absolute_error",
        # "max": "max_error"

    metric_df = dataframe[make_column_selector(pattern = f"param_|{metric}")]
    
    return metric_df[metric_df[f"rank_test_{metric}"] <= n_best].T











file_path = "data/Sofia 2021-01-01 to 2023-09-26.csv"


weather_data_raw = pd.read_csv(file_path)
weather_data_raw.head(2)


weather_data_raw.shape


weather_data_raw.columns


weather_data = weather_data_raw.copy()
weather_data.datetime = pd.to_datetime(weather_data.datetime)
weather_data.head()








weather_data_naive = weather_data[["datetime", "temp", "precip", "cloudcover"]]
weather_data_naive.isna().sum()


weather_data_naive = weather_data_naive.fillna(0)


lags = create_lags(weather_data_naive, ["temp", "precip", "cloudcover"], 1)


weather_data_naive = pd.concat([weather_data_naive, lags], axis = 1)
weather_data_naive





weather_data_naive.isna().sum()


weather_data_naive = weather_data_naive.dropna()
weather_data_naive


temp_actual = weather_data_naive.temp
temp_predicted = weather_data_naive.temp_1


r2_score(temp_actual, temp_predicted)


mean_squared_error(temp_actual, temp_predicted)


mean_absolute_error(temp_actual, temp_predicted)





max_error(temp_actual, temp_predicted)





# temp_actual


# def plot_residuals(y, y_pred):
#     plt.scatter(y, y_pred - y)





plot_residuals(temp_actual, temp_predicted, "Temperature")





plot_residuals_vs_time(temp_actual, temp_predicted, "Temperature", weather_data_naive)





precip_actual = weather_data_naive.precip
precip_predicted = weather_data_naive.precip_1


r2_score(precip_actual, precip_predicted)


mean_squared_error(precip_actual, precip_predicted)


mean_absolute_error(precip_actual, precip_predicted)


max_error(precip_actual, precip_predicted)


plot_residuals(precip_actual, precip_predicted, "Precipitation")


plot_residuals_vs_time(precip_actual, precip_predicted, "Precipitation", weather_data_naive)


cloudcover_actual = weather_data_naive.cloudcover
cloudcover_predicted = weather_data_naive.cloudcover_1


r2_score(cloudcover_actual, cloudcover_predicted)


mean_absolute_error(cloudcover_actual, cloudcover_predicted)


max_error(cloudcover_actual, cloudcover_predicted)


plot_residuals(cloudcover_actual, cloudcover_predicted, "Cloudcover")


plot_residuals_vs_time(cloudcover_actual, cloudcover_predicted, "Cloudcover", weather_data_naive)


























n_lags = 10
base_features = ["temp", "precip", "cloudcover"]
features_with_lag = [
    "tempmax", "tempmin", "temp", 
    "dew", "humidity", 
    "precip", "precipprob", "precipcover", "preciptype", 
    "snow", "snowdepth", 
    "windgust", "windspeed", "winddir", 
    "sealevelpressure", 
    "cloudcover", "visibility", 
    "conditions", "description", "icon"
]


# little cheat, impute with constant before lags
weather_data.preciptype = weather_data.preciptype.fillna("no_precip")


lags_df = create_lags(weather_data, features_with_lag, n_lags)
# lags_df


weather_data_with_lags_raw = pd.concat([weather_data, lags_df], axis = 1)
weather_data_with_lags_raw.head(3)


weather_data_with_lags_raw.shape





weather_data_with_lags = weather_data_with_lags_raw.drop(range(n_lags))


weather_data_with_lags = weather_data_with_lags.reset_index()


weather_data_with_lags["dt_year"] = weather_data_with_lags.datetime.dt.year # for visualisation of cv split


weather_data_with_lags.shape


weather_data_with_lags.head(3)











n_splits = 10
gap = 0
time_series_cv = TimeSeriesSplit(n_splits = n_splits, gap = gap)


fig = plt.figure()
ax = plt.subplot(111)

plot_cv_indices(time_series_cv, weather_data_with_lags, ax, fig, n_splits)

plt.show()











temp_column_selector = make_column_selector(pattern = "temp_") # select "temp_n", excluding "temp"


temp_transformer = Pipeline(
    steps=[
        ("impute", SimpleImputer(strategy = "mean")),
        ("scale", MinMaxScaler())
    ]
)


feature_preprocessor = ColumnTransformer(
    transformers=[
        ("temp", temp_transformer, temp_column_selector)
    ],
    verbose_feature_names_out = False,
    # sparse_threshold=0.0
)


weather_features = feature_preprocessor.fit_transform(weather_data_with_lags)


feature_preprocessor.get_feature_names_out()


weather_features.shape


temp_target = weather_data_with_lags.temp


pipe_autoregression = Pipeline(
    steps=[
        ("preprocess", feature_preprocessor),
        ("model", LinearRegression())
    ]
)








scoring_metrics = "r2", "neg_mean_squared_error", "neg_mean_absolute_error", "max_error"


cv_results_temperature = cross_validate(
    pipe_autoregression, # Estimator
    weather_data_with_lags, # X
    weather_data_with_lags.temp, # y
    scoring = scoring_metrics, 
    cv = time_series_cv, 
    return_train_score = True, 
    return_indices = True,
    return_estimator = True
)


plot_score_cv(cv_results_temperature)





plot_cv_predictions(cv_results_temperature, weather_data_with_lags, "temp", n_fold = 8)


plot_cv_predictions(cv_results_temperature, weather_data_with_lags, "temp", n_fold = 9)





feature_names = pipe_autoregression[-2].get_feature_names_out()


pd.DataFrame([estimator["model"].coef_ for estimator in cv_results_temperature["estimator"]], columns = feature_names).rename_axis("Fold_Index")

















precip_column_selector = make_column_selector(pattern = "precip_") # excluding "precip"


cloudcover_column_selector = make_column_selector(pattern = "cloudcover_") # excluding "cloudcover"


log_transformer = FunctionTransformer(np.log1p, feature_names_out="one-to-one")


precip_transformer = Pipeline(
    steps=[
        ("impute", SimpleImputer(strategy = "constant", fill_value = 0)),
        ("log_transform", log_transformer),
        ("scale", MinMaxScaler())
    ]
)


cloudcover_transformer = Pipeline(
    steps=[
        ("impute", SimpleImputer(strategy = "constant", fill_value = 0)),
        ("scale", MinMaxScaler())
    ]
)


feature_preprocessor = ColumnTransformer(
    transformers=[
        ("temp", temp_transformer, temp_column_selector),
        ("precip", precip_transformer, precip_column_selector),
        ("cloudcover", cloudcover_transformer, cloudcover_column_selector)
    ],
    verbose_feature_names_out = False,
    # sparse_threshold=0.0
)


pipe_linear_regression_base_features = Pipeline(
    steps=[
        ("preprocess", feature_preprocessor),
        ("model", LinearRegression())
    ]
)


# just checking, actual fit inside the cv
pipe_linear_regression_base_features.fit(weather_data_with_lags, weather_data_with_lags.temp)


pipe_linear_regression_base_features[:-1].get_feature_names_out()


cv_results_temperature = cross_validate(
    pipe_linear_regression_base_features, # Estimator
    weather_data_with_lags, # X
    weather_data_with_lags.temp, # y
    scoring = scoring_metrics, 
    cv = time_series_cv, 
    return_train_score = True, 
    return_indices = True,
    return_estimator = True
)


# cv_results_temperature


plot_score_cv(cv_results_temperature, target = "Temperature", skip_folds = 1)





plot_cv_predictions(cv_results_temperature,  weather_data_with_lags, "temp", n_fold = 8)


plot_cv_predictions(cv_results_temperature,  weather_data_with_lags, "temp", n_fold = 9)





feature_names = pipe_linear_regression_base_features[-2].get_feature_names_out()


coefficients_temp = pd.DataFrame([estimator["model"].coef_ for estimator in cv_results_temperature["estimator"]], columns = feature_names).rename_axis("Fold_Index")


coefficients_temp.filter(regex=("temp"))


coefficients_temp.filter(regex=("precip"))


coefficients_temp.filter(regex=("cloudcover"))





weather_data_with_lags.precip = weather_data_with_lags.precip.fillna(0)


cv_results_precip = cross_validate(
    pipe_linear_regression_base_features, # Estimator
    weather_data_with_lags, # X
    weather_data_with_lags.precip, # y
    scoring = scoring_metrics, 
    cv = time_series_cv, 
    return_train_score = True, 
    return_indices = True,
    return_estimator = True
)


plot_score_cv(cv_results_precip, target = "Precipitation")





plot_cv_predictions(cv_results_precip,  weather_data_with_lags, "precip", n_fold = 8)


plot_cv_predictions(cv_results_precip,  weather_data_with_lags, "precip", n_fold = 9)





weather_data_with_lags.cloudcover = weather_data_with_lags.cloudcover.fillna(0)


cv_results_cloudcover = cross_validate(
    pipe_linear_regression_base_features, # Estimator
    weather_data_with_lags, # X
    weather_data_with_lags.cloudcover, # y
    scoring = scoring_metrics, 
    cv = time_series_cv, 
    return_train_score = True, 
    return_indices = True,
    return_estimator = True
)


plot_score_cv(cv_results_cloudcover, target = "Cloudcover")


plot_cv_predictions(cv_results_cloudcover,  weather_data_with_lags, "cloudcover", n_fold = 8)


plot_cv_predictions(cv_results_cloudcover,  weather_data_with_lags, "cloudcover", n_fold = 9)














weather_data_with_lags["dt_year"] = weather_data_with_lags.datetime.dt.year  
weather_data_with_lags["dt_month"] = weather_data_with_lags.datetime.dt.month  
weather_data_with_lags["dt_week_of_year"] = weather_data_with_lags.datetime.dt.isocalendar().week 
weather_data_with_lags["dt_day_of_year"] = weather_data_with_lags.datetime.dt.day_of_year 





def sin_name_out(self, input_features):
    return [f"{feature}_sin" for feature in input_features]

def cos_name_out(self, input_features):
    return [f"{feature}_cos" for feature in input_features]


def sin_transformer(period):
    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi), feature_names_out = sin_name_out)


def cos_transformer(period):
    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi), feature_names_out = cos_name_out)




time_transformer = ColumnTransformer(
        transformers=[
            ("nominal", OneHotEncoder(handle_unknown="ignore", sparse_output=False), ["dt_year"]), # was ["dt_year", "dt_month"]
            ("week_sin", sin_transformer(52), ["dt_week_of_year"]),
            ("week_cos", cos_transformer(52), ["dt_week_of_year"]),
            ("day_sin", sin_transformer(365), ["dt_day_of_year"]),
            ("day_cos", cos_transformer(365), ["dt_day_of_year"]),
            ],
    verbose_feature_names_out = False
)





time_features = time_transformer.fit_transform(weather_data_with_lags) # just checking, actual fit inside cv


time_transformer.get_feature_names_out()


len(time_transformer.get_feature_names_out())


fig, axs = plt.subplots(1, 2, figsize=(10, 4), constrained_layout = True)

features = ["dt_week_of_year", "dt_day_of_year"]
titles = ["Encoding Week of Year", "Encoding Day of Year"]
sin_column_index = [3, 5]

for i, ax in enumerate(axs):
    scatter = ax.scatter(time_features[:,sin_column_index[i]], time_features[:,sin_column_index[i] + 1], c=weather_data_with_lags[features[i]])
    colorbar = fig.colorbar(scatter)
    
    ax.set_title(titles[i])
    ax.set_aspect("equal")
    ax.set(
        xlabel="sin(week_of_year)",
        ylabel="cos(week_of_year)",
    )

plt.show()


plt.plot(weather_data_with_lags.index, time_features[:,3], c = "lime", label = "dt_week_of_year_sin")
plt.plot(weather_data_with_lags.index, time_features[:,4], c = "red", label = "dt_week_of_year_cos")

plt.plot(weather_data_with_lags.index, time_features[:,5], label = "dt_day_of_year_sin")
plt.plot(weather_data_with_lags.index, time_features[:,6], label = "dt_week_of_year_cos")

plt.xlabel("sample index [days]")
plt.title("Trigonometric encoding")
plt.legend(bbox_to_anchor=(1.1, 1))

plt.show()





pipe_linear_time_features = Pipeline(
    steps=[
        ("time_transform", time_transformer),
        ("model", LinearRegression())
    ]
)


pipe_linear_time_features.fit(weather_data_with_lags, weather_data_with_lags.temp) # just checking


# pipe_linear_time_features["model"].coef_


# pipe_linear_time_features["model"].intercept_


pipe_linear_time_features["model"].n_features_in_


cv_results_temperature = cross_validate(
    pipe_linear_time_features, # Estimator
    weather_data_with_lags, # X
    weather_data_with_lags.temp, # y
    scoring = scoring_metrics, 
    cv = time_series_cv, 
    return_train_score = True, 
    return_indices = True,
    return_estimator = True
)


plot_score_cv(cv_results_temperature)


plot_cv_predictions(cv_results_temperature, weather_data_with_lags, "temp", n_fold = 8)


plot_cv_predictions(cv_results_temperature, weather_data_with_lags, "temp", n_fold = 9)





feature_names = pipe_linear_time_features[-2].get_feature_names_out()


pd.DataFrame([cv_results_temperature["estimator"][i]["model"].coef_ for i in range(10)], columns = feature_names)





cv_results_precip = cross_validate(
    pipe_linear_time_features, # Estimator
    weather_data_with_lags, # X
    weather_data_with_lags.precip, # y
    scoring = scoring_metrics, 
    cv = time_series_cv, 
    return_train_score = True, 
    return_indices = True,
    return_estimator = True
)


plot_score_cv(cv_results_precip, target = "precip")


plot_cv_predictions(cv_results_precip, weather_data_with_lags, "precip", n_fold = 8)


plot_cv_predictions(cv_results_precip, weather_data_with_lags, "precip", n_fold = 9)





pd.DataFrame([cv_results_precip["estimator"][i]["model"].coef_ for i in range(10)], columns = feature_names)





cv_results_cloudcover = cross_validate(
    pipe_linear_time_features, # Estimator
    weather_data_with_lags, # X
    weather_data_with_lags.cloudcover, # y
    scoring = scoring_metrics, 
    cv = time_series_cv, 
    return_train_score = True, 
    return_indices = True,
    return_estimator = True
)


# plot_score_cv(cv_results_cloudcover)


plot_cv_predictions(cv_results_cloudcover, weather_data_with_lags, "cloudcover", n_fold = 8)


plot_cv_predictions(cv_results_cloudcover, weather_data_with_lags, "cloudcover", n_fold = 9)





pd.DataFrame([cv_results_cloudcover["estimator"][i]["model"].coef_ for i in range(10)], columns = feature_names)














n_lags


numeric_normal = [
    "tempmax",
     "tempmin",
     "temp",
     "dew",
     "humidity",
     "windspeed",
     "sealevelpressure",
     "cloudcover"    
]
numeric_log_features = [
    "precip",
    "snow",
    "snowcover"
]
numeric_cyclic_features = [
    "winddir"
]
categorical_features = [
    "preciptype",
    "conditions"
]
text_features = [
    "description"
]


# make_column_selector(pattern = "sno|temp")(weather_data_with_lags)


def lag_column_selector(lag_features): # ugly but it's working
   return  make_column_selector(pattern = "|".join([f"{feature}_" for feature in lag_features]))


# lag_column_selector(numeric_normal)(weather_data_with_lags)





preprozess_time_features = ColumnTransformer(
            transformers=[
                ("categorical", OneHotEncoder(handle_unknown="ignore", sparse_output=False), ["dt_month", "dt_year"]),
                ("day_sin", sin_transformer(365), ["dt_day_of_year"]),
                ("day_cos", cos_transformer(365), ["dt_day_of_year"]),
            ],
    verbose_feature_names_out = False
)





preprozess_numeric_normal = Pipeline(
            steps=[
                ("impute", SimpleImputer(strategy = "constant", fill_value = 0)),
                ("scale", MinMaxScaler())
            ]
)





preprozess_numeric_log = Pipeline(
            steps=[
                ("impute", SimpleImputer(strategy = "constant", fill_value = 0)),
                ("log_transform", FunctionTransformer(np.log1p, feature_names_out = "one-to-one"))
            ]
)





preprozess_numeric_cyclic = ColumnTransformer(  # TODO: remove hardcode
            transformers=[
                ("winddir_sin", sin_transformer(360), make_column_selector(pattern = "winddir")),
                ("winddir_cos", cos_transformer(360), make_column_selector(pattern = "winddir")),
            ],
    verbose_feature_names_out = False
)


# preprozess_numeric_cyclic.fit_transform(weather_data_with_lags)


# preprozess_numeric_cyclic.get_feature_names_out()





token_pattern = r"(?u)\b[^,]+\b" # honorable mention to ChatGPT for outstanding knowledge in the field of RegEx patterns
# pattern means we keep words separated by space in single token (like "partially cloudy") and split only by comma


count_vec_test = CountVectorizer(token_pattern = token_pattern)


count_vec_test.fit_transform([
    "first, words with space,noSpaceAfterComma, word, word, lastWord", 
    "firstWord, words with space,noSpaceAfterComma, UPPerCase, lastWord"]).toarray()


count_vec_test.vocabulary_


multi_column_vectorizer = ColumnTransformer(
            transformers=[
                (x, CountVectorizer(token_pattern = token_pattern), x) for x in lag_column_selector(categorical_features)(weather_data_with_lags)
            ],
    verbose_feature_names_out = True
)


multi_column_vectorizer.fit_transform(weather_data_with_lags).shape


len(multi_column_vectorizer.get_feature_names_out())


# "multi_column_vectorizer" needs to be first step in pipeline to work - input pd with column names not np
# Couldn't make it work with all columns / array - spent too much time in that rabbit hole
# Maybe should have made custom transformer instead of using CountVectorizr, but it's too late now

# preprozess_categorical = Pipeline(
#             steps=[
#                 ("impute", SimpleImputer(strategy = "constant", fill_value = "None")),
#                 ("multi_column_vectorizer", multi_column_vectorizer),
#             ]
# )





# Maybe add gazillion more columns with tfidf on description

# ColumnTransformer([(x, TfidfVectorizer(), x) for x in textual_columns])





preprozess_all_features = ColumnTransformer(
            transformers=[
                ("time_features", preprozess_time_features, make_column_selector(pattern = "dt_")),
                ("numeric_normal", preprozess_numeric_normal, lag_column_selector(numeric_normal)),
                ("numeric_log", preprozess_numeric_log, lag_column_selector(numeric_log_features)),
                ("numeric_cyclic", preprozess_numeric_cyclic, lag_column_selector(numeric_cyclic_features)),
                ("categorical", multi_column_vectorizer, lag_column_selector(categorical_features))
            ],
    verbose_feature_names_out = False
)





preprozess_all_features.fit(weather_data_with_lags)


preprozess_all_features.transform(weather_data_with_lags).shape





pipe_linear_all_features = Pipeline(
    steps=[
        ("preprocess", preprozess_all_features),
        ("model", LinearRegression())
    ]
)





cv_results_temp = run_cv_experiment(
    pipe_linear_all_features, 
    weather_data_with_lags, 
    weather_data_with_lags.temp,
    time_series_cv, 
    experiment_name = "end_linear_all", 
    target_name = "temp",
    
    log_experiment = True # False for rerunning the notebook
)


plot_score_cv(cv_results_temp)





plot_score_cv(cv_results_temp, skip_folds = 7)


plot_cv_predictions(cv_results_temp, weather_data_with_lags, "temp", n_fold = 8)


plot_cv_predictions(cv_results_temp, weather_data_with_lags, "temp", n_fold = 9)





cv_results_precip = run_cv_experiment(
    pipe_linear_all_features, 
    weather_data_with_lags, 
    weather_data_with_lags.precip,
    time_series_cv, 
    experiment_name = "end_linear_all_features", 
    target_name = "precip",

    log_experiment = True
) 


plot_score_cv(cv_results_precip, target = "precip", skip_folds = 7)


plot_cv_predictions(cv_results_precip, weather_data_with_lags, "precip", n_fold = 8)


plot_cv_predictions(cv_results_precip, weather_data_with_lags, "precip", n_fold = 9)





cv_results_cloudcover = run_cv_experiment(
    pipe_linear_all_features, 
    weather_data_with_lags, 
    weather_data_with_lags.cloudcover,
    time_series_cv, 
    experiment_name = "linear_all_features", 
    target_name = "cloudcover",
    
    log_experiment = True
) 


plot_score_cv(cv_results_cloudcover, skip_folds = 7)


plot_cv_predictions(cv_results_cloudcover, weather_data_with_lags, "cloudcover", n_fold = 9)





pipe_pca = Pipeline(
    steps=[
        ("preprocess", preprozess_all_features),
        ("pca", PCA())
    ]
)


pca = pipe_pca.fit(weather_data_with_lags)


pca.n_features_in_


variance_ratio = np.cumsum(pipe_pca["pca"].explained_variance_ratio_)


plt.plot(variance_ratio)
plt.xlabel("n components")
plt.ylabel("explained variance ratio sum")
plt.show()


variance_ratio[100]


# pd.DataFrame(pipe_pca["pca"].components_, columns = pipe_pca["preprocess"].get_feature_names_out())


pipe_poly_pca = Pipeline(
    steps=[
        ("preprocess", preprozess_all_features),
        ("polynomials", PolynomialFeatures(degree = 2, interaction_only = False)),
        ("pca", PCA())
    ]
)


poly_pca = pipe_poly_pca.fit(weather_data_with_lags)


poly_pca["pca"].n_features_in_


variance_ratio = np.cumsum(pipe_poly_pca["pca"].explained_variance_ratio_)


plt.plot(variance_ratio)
plt.xlabel("n components")
plt.ylabel("explained variance ratio sum")
plt.show()


variance_ratio[600]


# pipe_poly_3_pca = Pipeline(  
#     steps=[
#         ("preprocess", preprozess_all_features),
#         ("polynomials", PolynomialFeatures(degree = 3, interaction_only = False)),
#         ("pca", PCA())
#     ]
# )


# pipe_poly_3_pca.fit(weather_data_with_lags) # my 10-year old machine says NO





# model_pca = Pipeline(
#     steps=[
#         ("preprocess", preprozess_all_features),
#         ("pca", PCA(n_components = None)),
#         ("model", LinearRegression())
#     ]
# )


model_pca_poly = Pipeline(
    steps=[
        ("preprocess", preprozess_all_features),
        ("pca", KernelPCA(n_components = None, kernel = "poly", degree = 2)),
        ("model", LinearRegression())
    ]
)


model_pca_rbf = Pipeline(
    steps=[
        ("preprocess", preprozess_all_features),
        ("pca", KernelPCA(n_components = None, kernel = "rbf", gamma = None)),
        ("model", LinearRegression())
    ]
)





cv_results_temp = run_cv_experiment(
    model_pca_poly, 
    weather_data_with_lags, 
    weather_data_with_lags.temp, 
    cv = time_series_cv,
    experiment_name = "end_model_pca_poly",

    log_experiment = True
)


plot_score_cv(cv_results_temp, skip_folds = 0)





plot_cv_predictions(cv_results_temp, weather_data_with_lags, "temp", n_fold = 8)


plot_cv_predictions(cv_results_temp, weather_data_with_lags, "temp", n_fold = 9)





cv_results_precip = run_cv_experiment(
    model_pca_poly, 
    weather_data_with_lags, 
    weather_data_with_lags.precip,
    time_series_cv, 
    experiment_name = "end_model_pca_poly", 
    target_name = "precip",

    log_experiment = True
) 


plot_score_cv(cv_results_precip, skip_folds = 0)


plot_cv_predictions(cv_results_precip, weather_data_with_lags, "precip", n_fold = 8)


plot_cv_predictions(cv_results_precip, weather_data_with_lags, "precip", n_fold = 9)





cv_results_cloudcover = run_cv_experiment(
    model_pca_poly, 
    weather_data_with_lags, 
    weather_data_with_lags.cloudcover,
    time_series_cv, 
    experiment_name = "end_model_pca_poly", 
    target_name = "cloudcover",

    log_experiment = True
)


plot_score_cv(cv_results_cloudcover, skip_folds = 1)


plot_cv_predictions(cv_results_cloudcover, weather_data_with_lags, "cloudcover", n_fold = 8)


plot_cv_predictions(cv_results_cloudcover, weather_data_with_lags, "cloudcover", n_fold = 9)





time_series_indices = [fold_indices for fold_indices in time_series_cv.split(weather_data_with_lags)][5:]
# time_series_indices[0]


ridge_pca_poly = Pipeline(
    steps=[
        ("preprocess", preprozess_all_features),
        ("pca", KernelPCA(degree = 2)),
        ("ridge", Ridge())
    ]
)


param_grid = {
    "pca__n_components": [50, 100, 200, None],
    "ridge__alpha": [0.001, 0.01, 0.1, 1, 10, 100]
}


# param_grid = {
#     "pca__kernel": ["poly", "rbf"],
#     "pca__degree": [2, 3, 4],
#     "pca__gamma": [1e-3, 1e-2, 1e-1, 1, 10, 100],
#     "pca__n_components": [100, 200, None],
#     "ridge__alpha": [0.001, 0.01, 1, 10]
# }





param_grid_temp = {
    "pca__kernel": ["poly"],
    "pca__degree": [2],
    "pca__n_components": [160, 170, 180, 190, 200, None],
    "ridge__alpha": [0.04, 0.05, 0.06, 0.07, 0.08]
}


# grid_search = GridSearchCV(
#     ridge_pca_poly, 
#     param_grid = param_grid,
#     cv = time_series_indices[4:],
#     scoring = scoring_metrics,
#     refit = "neg_mean_squared_error", # choose best model based on mse
#     return_train_score = True
# )


experiment_temp = mlflow.create_experiment(name = "end_grid_search_temp")
experiment_temp


grid_search_temp, grid_search_results_temp = run_grid_search(
    ridge_pca_poly,
    weather_data_with_lags,
    weather_data_with_lags.temp,
    param_grid_temp,
    time_series_indices,
    scoring_metrics = ("r2", "neg_mean_squared_error", "neg_mean_absolute_error", "max_error"),
    run_name = "large_f", 
    target = "temp",
    pca_kernel = "poly_2",
    log_run = True,
    experiment = experiment_temp)


best_params_temp = grid_search_temp.best_params_
best_params_temp





filter_grid_search_df(grid_search_results_temp)


filter_grid_search_df(grid_search_results_temp, metric = "neg_mean_squared_error")


filter_grid_search_df(grid_search_results_temp, metric = "neg_mean_absolute_error")





cv_results_temp = run_cv_experiment(
    grid_search_temp.best_estimator_, 
    weather_data_with_lags, 
    weather_data_with_lags.temp, 
    cv = time_series_cv,
    experiment_name = "end_grid_",
    target_name = "temp",

    log_experiment = True
)


plot_score_cv(cv_results_temp, skip_folds = 5)


plot_cv_predictions(cv_results_temp, weather_data_with_lags, "temp", n_fold = 8)


plot_cv_predictions(cv_results_temp, weather_data_with_lags, "temp", n_fold = 9)





param_grid_precip = {
    "pca__kernel": ["poly"],
    "pca__degree": [2],
    "pca__n_components": [180, 190, 200, None],
}


experiment_precip = mlflow.create_experiment(name = "end_grid_search_precip")
experiment_precip


grid_search_precip, grid_search_results_precip = run_grid_search(
    model_pca_poly,
    weather_data_with_lags,
    weather_data_with_lags.precip,
    param_grid_precip,
    time_series_indices,
    scoring_metrics = ("r2", "neg_mean_squared_error", "neg_mean_absolute_error", "max_error"),
    run_name = "lin_reg", 
    target = "precip",
    pca_kernel = "poly",
    log_run = True,
    experiment = experiment_precip)


grid_search_precip.best_params_


filter_grid_search_df(grid_search_results_precip, metric = "r2")


filter_grid_search_df(grid_search_results_precip, metric = "neg_mean_squared_error")


cv_results_precip = run_cv_experiment(
    grid_search_precip.best_estimator_, 
    weather_data_with_lags, 
    weather_data_with_lags.precip, 
    cv = time_series_cv,
    experiment_name = "end_gridsearch_final",
    target_name = "precip",

    log_experiment = True
)


plot_score_cv(cv_results_precip, target = "precip")


plot_cv_predictions(cv_results_precip, weather_data_with_lags, "precip", n_fold = 8)


plot_cv_predictions(cv_results_precip, weather_data_with_lags, "precip", n_fold = 9)





param_grid_cloudcover = {
    "pca__kernel": ["poly"],
    "pca__degree": [2],
    "pca__n_components": [160, 200, None],
    "ridge__alpha": [0.02, 0.04, 1, 4]
}


experiment_cc = mlflow.create_experiment(name = "end_grid_search_cloudcover")
experiment_cc


grid_search_cloudcover, grid_search_results_cloudcover = run_grid_search(
    ridge_pca_poly,
    weather_data_with_lags,
    weather_data_with_lags.cloudcover,
    param_grid_cloudcover,
    time_series_indices,
    scoring_metrics = ("r2", "neg_mean_squared_error", "neg_mean_absolute_error", "max_error"),
    run_name = "gridsearch_final_", 
    target = "cloudcover",
    pca_kernel = "mix",
    log_run = True,
    experiment = experiment_cc)


grid_search_cloudcover.best_params_


filter_grid_search_df(grid_search_results_cloudcover, metric = "r2")


filter_grid_search_df(grid_search_results_cloudcover, metric = "neg_mean_squared_error")


cv_results_cloudcover = run_cv_experiment(
    grid_search_cloudcover.best_estimator_, 
    weather_data_with_lags, 
    weather_data_with_lags.cloudcover, 
    cv = time_series_cv,
    experiment_name = "end_gridsearch_final",
    target_name = "cloudcover",

    log_experiment = True
)


plot_score_cv(cv_results_cloudcover, target = "cloudcover", skip_folds = 5)


plot_cv_predictions(cv_results_cloudcover, weather_data_with_lags, "cloudcover", n_fold = 8)


plot_cv_predictions(cv_results_cloudcover, weather_data_with_lags, "cloudcover", n_fold = 9)











best_model_temp = grid_search_temp.best_estimator_
best_model_precip = grid_search_precip.best_estimator_
best_model_cloudcover = grid_search_cloudcover.best_estimator_





# from joblib import dump, load


# dump(best_model, 'final_model_precip.joblib')

# PicklingError: Can't pickle <function sin_transformer.<locals>.<lambda> at 0x0000026114653CE0>: it's not found as __main__.sin_transformer.<locals>.<lambda>






weather_data_test_raw = pd.read_csv("data\Sofia 2023-10-01 to 2023-12-13.csv")


weather_data_test_raw[weather_data_test_raw.temp.isna()]





weather_data_test_raw = weather_data_test_raw.dropna(subset = ["temp"])





weather_data_test_raw["precip"] = weather_data_test_raw["precip"].fillna(0)
weather_data_test_raw["preciptype"] = weather_data_test_raw["preciptype"].fillna("None")
weather_data_test_raw["conditions"] = weather_data_test_raw["conditions"].fillna("None")



# why is this not in the pipeline, why?!

lags_test = create_lags(weather_data_test_raw, features_with_lag, n_lags)
weather_data_test = pd.concat([weather_data_test_raw, lags_test], axis = 1)
weather_data_test = weather_data_test.drop(range(n_lags))
weather_data_test = weather_data_test.reset_index()
weather_data_test.datetime = pd.to_datetime(weather_data_test.datetime)
weather_data_test["dt_year"] = weather_data_test.datetime.dt.year  
weather_data_test["dt_month"] = weather_data_test.datetime.dt.month 
weather_data_test["dt_week_of_year"] = weather_data_test.datetime.dt.isocalendar().week 
weather_data_test["dt_day_of_year"] = weather_data_test.datetime.dt.day_of_year
weather_data_test.head(3)


assert weather_data_test.shape[1] == weather_data_with_lags.shape[1]


weather_data_test.isna().sum().sum()


predictions_temp = best_model_temp.predict(weather_data_test)


best_model_temp.score(weather_data_test, weather_data_test.temp)


def plot_predictions(estimator, input_dataframe, target_column):
    plt.figure(figsize=(13, 4))

    
    plt.plot(input_dataframe.datetime, input_dataframe[target_column], c = "lime", lw = 1, label = "actual values") # y_true
    
    predictions_test = estimator.predict(input_dataframe)
    plt.plot(input_dataframe.datetime, predictions_test, lw = 1, c = "orange", label = "predictions test set")

    plt.title(f"Predictions of Final Model")
    plt.ylabel(target_column)
    plt.legend()

    plt.show()


plot_predictions(best_model_temp, weather_data_test, "temp")


plot_residuals(weather_data_test.temp, predictions_temp, "temp")





plot_residuals_vs_time(weather_data_test.temp, predictions_temp, "temp", weather_data_test)





predictions_precip = best_model_precip.predict(weather_data_test)


plot_predictions(best_model_precip, weather_data_test, "precip")


plot_residuals(weather_data_test.precip, predictions_precip, "precip")


plot_residuals_vs_time(weather_data_test.precip, predictions_precip, "precip", weather_data_test)





predictions_cloudcover = best_model_cloudcover.predict(weather_data_test)


plot_predictions(best_model_cloudcover, weather_data_test, "cloudcover")


plot_residuals(weather_data_test.cloudcover, predictions_cloudcover, "cloudcover")


plot_residuals_vs_time(weather_data_test.cloudcover, predictions_cloudcover, "cloudcover", weather_data_test)


















